
#Configuring Google Cloud Data Flow Options

dataflow.job.project.id=bigquery-331010
dataflow.job.name=gcptobq
dataflow.job.temp.location=gs://mayuri_120199_new/temp/
dataflow.job.stg.location=gs://mayuri_120199_new/staging/
dataflow.job.region=us-east1
dataflow.job.publicip.use=true
dataflow.job.max.worker=2
dataflow.job.worker.machine.type=n1-standard-1
dataflow.job.subnetwork.enable=false
dataflow.job.subnetwork.string=
dataflow.job.serviceaccount=dataflow-service@bigquery-331010.iam.gserviceaccount.com

#Configuration process Type
dataflow.job.type.streaming=false
dataflow.job.reader=gcs,gcs
dataflow.job.transform=csv2bq
dataflow.job.writer=gcs,bq

#Configuring Source 
dataflow.job.gcsreadfile=gs://mayuri_120199_new/csv/user*.csv,gs://mayuri_120199_new/csv/user*.csv

#Source Properities
dataflow.csv.delimiter=,
dataflow.csv.removequotes=true
dataflow.csv.source_system_code=manual
dataflow.csv.skip.leading.row=true
dataflow.csv.skip.leading.row.number=1

#Configuring Destination File
dataflow.job.gcswritefile=gs://mayuri_120199_new/csv/output/
	
#Configuring Big Query Table
dataflow.job.tablename=bigquery-331010:poc.gcspoc_new
dataflow.job.schema.file=gs://mayuri_120199_new/config/config_sc.json
